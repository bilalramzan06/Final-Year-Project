{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load data from output_labels.csv\n",
    "csv_path = 'D:\\\\Semester 7\\\\FYP\\\\preprocessing\\\\output_labels.csv'\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# Extract file paths and class labels\n",
    "file_paths = df['Path'].values\n",
    "class_labels = df['Class'].values\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ECG data from file paths and extract features\n",
    "ecg_features = []\n",
    "for path in file_paths:\n",
    "    # Load ECG data from CSV file\n",
    "    ecg_df = pd.read_csv(path)\n",
    "    # Assuming your ECG data is in columns I, II, III, AVR, AVL, AVF, V1, V2, V3, V4, V5, V6\n",
    "    ecg_values = ecg_df[['I', 'II', 'III', 'AVR', 'AVL',\n",
    "                         'AVF', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6']].values\n",
    "    # Extract features from the ECG data (e.g., mean, standard deviation, etc.)\n",
    "    ecg_mean = np.mean(ecg_values, axis=0)\n",
    "    ecg_std = np.std(ecg_values, axis=0)\n",
    "    # Concatenate features\n",
    "    ecg_features.append(np.concatenate([ecg_mean, ecg_std]))\n",
    "\n",
    "X = np.array(ecg_features)\n",
    "y = np.array(class_labels)\n",
    "\n",
    "# Optionally, scale the features using StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.06754309e-01,  9.69585026e-02, -1.25811360e-02, ...,\n",
       "        -1.16013252e+00, -1.18701520e+00, -8.38663361e-01],\n",
       "       [-1.70182387e-01, -9.01460947e-02,  9.14431702e-04, ...,\n",
       "        -9.19763161e-02, -3.07549390e-01, -3.53556941e-01],\n",
       "       [-1.21854980e-01,  2.06285802e-01,  2.53099175e-01, ...,\n",
       "        -8.98325954e-01, -1.04995899e+00, -8.49920934e-01],\n",
       "       ...,\n",
       "       [-2.89177801e-01, -2.14743516e-01, -5.63262283e-02, ...,\n",
       "         2.78287179e-01,  1.43628759e+00,  1.10416308e+00],\n",
       "       [ 1.41885582e-02,  6.32782419e-02,  5.18875556e-02, ...,\n",
       "         4.66353588e+00,  4.97029829e+00,  2.56540120e+00],\n",
       "       [ 4.41830617e-01, -1.38549255e-01, -3.49866983e-01, ...,\n",
       "         3.02153652e-03, -6.66710737e-01, -8.74664481e-01]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(X_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.206754</td>\n",
       "      <td>0.096959</td>\n",
       "      <td>-0.012581</td>\n",
       "      <td>-0.173181</td>\n",
       "      <td>0.091168</td>\n",
       "      <td>0.041965</td>\n",
       "      <td>-0.026813</td>\n",
       "      <td>0.449883</td>\n",
       "      <td>0.062626</td>\n",
       "      <td>0.003041</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.964034</td>\n",
       "      <td>-0.822660</td>\n",
       "      <td>-0.682865</td>\n",
       "      <td>-1.113445</td>\n",
       "      <td>-0.666968</td>\n",
       "      <td>-0.510575</td>\n",
       "      <td>-0.993973</td>\n",
       "      <td>-1.160133</td>\n",
       "      <td>-1.187015</td>\n",
       "      <td>-0.838663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.170182</td>\n",
       "      <td>-0.090146</td>\n",
       "      <td>0.000914</td>\n",
       "      <td>0.153131</td>\n",
       "      <td>-0.069186</td>\n",
       "      <td>-0.045596</td>\n",
       "      <td>0.039148</td>\n",
       "      <td>0.628873</td>\n",
       "      <td>0.716911</td>\n",
       "      <td>0.028278</td>\n",
       "      <td>...</td>\n",
       "      <td>0.480555</td>\n",
       "      <td>0.655415</td>\n",
       "      <td>-0.279216</td>\n",
       "      <td>1.078422</td>\n",
       "      <td>0.021002</td>\n",
       "      <td>0.540156</td>\n",
       "      <td>0.231093</td>\n",
       "      <td>-0.091976</td>\n",
       "      <td>-0.307549</td>\n",
       "      <td>-0.353557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.121855</td>\n",
       "      <td>0.206286</td>\n",
       "      <td>0.253099</td>\n",
       "      <td>-0.119584</td>\n",
       "      <td>-0.248062</td>\n",
       "      <td>0.237345</td>\n",
       "      <td>-0.016906</td>\n",
       "      <td>0.060585</td>\n",
       "      <td>-0.088512</td>\n",
       "      <td>0.024158</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.250550</td>\n",
       "      <td>-0.367934</td>\n",
       "      <td>-0.393314</td>\n",
       "      <td>-0.136405</td>\n",
       "      <td>-0.646890</td>\n",
       "      <td>-0.855191</td>\n",
       "      <td>-0.745888</td>\n",
       "      <td>-0.898326</td>\n",
       "      <td>-1.049959</td>\n",
       "      <td>-0.849921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.017127</td>\n",
       "      <td>0.578436</td>\n",
       "      <td>0.548099</td>\n",
       "      <td>-0.476764</td>\n",
       "      <td>-0.438633</td>\n",
       "      <td>0.581166</td>\n",
       "      <td>-0.055818</td>\n",
       "      <td>-0.524953</td>\n",
       "      <td>0.316698</td>\n",
       "      <td>0.166236</td>\n",
       "      <td>...</td>\n",
       "      <td>2.834743</td>\n",
       "      <td>2.130513</td>\n",
       "      <td>1.114485</td>\n",
       "      <td>3.835736</td>\n",
       "      <td>-0.230339</td>\n",
       "      <td>0.563578</td>\n",
       "      <td>1.188964</td>\n",
       "      <td>2.008685</td>\n",
       "      <td>1.217559</td>\n",
       "      <td>0.642179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.171768</td>\n",
       "      <td>-0.059313</td>\n",
       "      <td>0.030015</td>\n",
       "      <td>0.128042</td>\n",
       "      <td>-0.091558</td>\n",
       "      <td>-0.013456</td>\n",
       "      <td>0.004489</td>\n",
       "      <td>0.039884</td>\n",
       "      <td>0.058966</td>\n",
       "      <td>0.035455</td>\n",
       "      <td>...</td>\n",
       "      <td>0.490352</td>\n",
       "      <td>0.249902</td>\n",
       "      <td>-0.564612</td>\n",
       "      <td>1.114390</td>\n",
       "      <td>-0.479082</td>\n",
       "      <td>0.133153</td>\n",
       "      <td>-0.542894</td>\n",
       "      <td>-0.333704</td>\n",
       "      <td>-0.376796</td>\n",
       "      <td>-0.351644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>-0.022383</td>\n",
       "      <td>0.100978</td>\n",
       "      <td>0.105341</td>\n",
       "      <td>-0.080219</td>\n",
       "      <td>-0.092091</td>\n",
       "      <td>0.104558</td>\n",
       "      <td>0.066948</td>\n",
       "      <td>0.567965</td>\n",
       "      <td>0.549913</td>\n",
       "      <td>0.006847</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002272</td>\n",
       "      <td>0.261772</td>\n",
       "      <td>-0.029450</td>\n",
       "      <td>0.142246</td>\n",
       "      <td>0.699077</td>\n",
       "      <td>0.996773</td>\n",
       "      <td>0.166256</td>\n",
       "      <td>1.280191</td>\n",
       "      <td>0.274554</td>\n",
       "      <td>-0.328118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>-0.211669</td>\n",
       "      <td>-0.542452</td>\n",
       "      <td>-0.400706</td>\n",
       "      <td>0.557486</td>\n",
       "      <td>0.234623</td>\n",
       "      <td>-0.481384</td>\n",
       "      <td>0.014808</td>\n",
       "      <td>-0.888904</td>\n",
       "      <td>-1.008548</td>\n",
       "      <td>-0.061814</td>\n",
       "      <td>...</td>\n",
       "      <td>0.387149</td>\n",
       "      <td>-0.192686</td>\n",
       "      <td>0.153088</td>\n",
       "      <td>0.414960</td>\n",
       "      <td>-0.179018</td>\n",
       "      <td>1.098301</td>\n",
       "      <td>0.604371</td>\n",
       "      <td>0.225461</td>\n",
       "      <td>-0.226670</td>\n",
       "      <td>-0.416019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>-0.289178</td>\n",
       "      <td>-0.214744</td>\n",
       "      <td>-0.056326</td>\n",
       "      <td>0.310154</td>\n",
       "      <td>-0.065822</td>\n",
       "      <td>-0.134256</td>\n",
       "      <td>0.018590</td>\n",
       "      <td>-0.042816</td>\n",
       "      <td>-0.052390</td>\n",
       "      <td>-0.001779</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.563077</td>\n",
       "      <td>2.416034</td>\n",
       "      <td>0.298032</td>\n",
       "      <td>0.256927</td>\n",
       "      <td>0.185960</td>\n",
       "      <td>-0.227742</td>\n",
       "      <td>-0.293569</td>\n",
       "      <td>0.278287</td>\n",
       "      <td>1.436288</td>\n",
       "      <td>1.104163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>0.014189</td>\n",
       "      <td>0.063278</td>\n",
       "      <td>0.051888</td>\n",
       "      <td>-0.061410</td>\n",
       "      <td>-0.031869</td>\n",
       "      <td>0.059184</td>\n",
       "      <td>-0.055970</td>\n",
       "      <td>-0.359431</td>\n",
       "      <td>-0.397514</td>\n",
       "      <td>0.012070</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.348479</td>\n",
       "      <td>3.271440</td>\n",
       "      <td>0.614907</td>\n",
       "      <td>0.661162</td>\n",
       "      <td>1.687657</td>\n",
       "      <td>1.181948</td>\n",
       "      <td>1.291810</td>\n",
       "      <td>4.663536</td>\n",
       "      <td>4.970298</td>\n",
       "      <td>2.565401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>0.441831</td>\n",
       "      <td>-0.138549</td>\n",
       "      <td>-0.349867</td>\n",
       "      <td>-0.077390</td>\n",
       "      <td>0.446202</td>\n",
       "      <td>-0.255219</td>\n",
       "      <td>0.074508</td>\n",
       "      <td>0.182363</td>\n",
       "      <td>0.200313</td>\n",
       "      <td>-0.001031</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.254312</td>\n",
       "      <td>-1.092190</td>\n",
       "      <td>-0.669170</td>\n",
       "      <td>-0.148257</td>\n",
       "      <td>-0.536119</td>\n",
       "      <td>-0.268133</td>\n",
       "      <td>-0.066321</td>\n",
       "      <td>0.003022</td>\n",
       "      <td>-0.666711</td>\n",
       "      <td>-0.874664</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6   \\\n",
       "0     0.206754  0.096959 -0.012581 -0.173181  0.091168  0.041965 -0.026813   \n",
       "1    -0.170182 -0.090146  0.000914  0.153131 -0.069186 -0.045596  0.039148   \n",
       "2    -0.121855  0.206286  0.253099 -0.119584 -0.248062  0.237345 -0.016906   \n",
       "3    -0.017127  0.578436  0.548099 -0.476764 -0.438633  0.581166 -0.055818   \n",
       "4    -0.171768 -0.059313  0.030015  0.128042 -0.091558 -0.013456  0.004489   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "4995 -0.022383  0.100978  0.105341 -0.080219 -0.092091  0.104558  0.066948   \n",
       "4996 -0.211669 -0.542452 -0.400706  0.557486  0.234623 -0.481384  0.014808   \n",
       "4997 -0.289178 -0.214744 -0.056326  0.310154 -0.065822 -0.134256  0.018590   \n",
       "4998  0.014189  0.063278  0.051888 -0.061410 -0.031869  0.059184 -0.055970   \n",
       "4999  0.441831 -0.138549 -0.349867 -0.077390  0.446202 -0.255219  0.074508   \n",
       "\n",
       "            7         8         9   ...        14        15        16  \\\n",
       "0     0.449883  0.062626  0.003041  ... -0.964034 -0.822660 -0.682865   \n",
       "1     0.628873  0.716911  0.028278  ...  0.480555  0.655415 -0.279216   \n",
       "2     0.060585 -0.088512  0.024158  ... -0.250550 -0.367934 -0.393314   \n",
       "3    -0.524953  0.316698  0.166236  ...  2.834743  2.130513  1.114485   \n",
       "4     0.039884  0.058966  0.035455  ...  0.490352  0.249902 -0.564612   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "4995  0.567965  0.549913  0.006847  ...  0.002272  0.261772 -0.029450   \n",
       "4996 -0.888904 -1.008548 -0.061814  ...  0.387149 -0.192686  0.153088   \n",
       "4997 -0.042816 -0.052390 -0.001779  ... -0.563077  2.416034  0.298032   \n",
       "4998 -0.359431 -0.397514  0.012070  ... -0.348479  3.271440  0.614907   \n",
       "4999  0.182363  0.200313 -0.001031  ... -0.254312 -1.092190 -0.669170   \n",
       "\n",
       "            17        18        19        20        21        22        23  \n",
       "0    -1.113445 -0.666968 -0.510575 -0.993973 -1.160133 -1.187015 -0.838663  \n",
       "1     1.078422  0.021002  0.540156  0.231093 -0.091976 -0.307549 -0.353557  \n",
       "2    -0.136405 -0.646890 -0.855191 -0.745888 -0.898326 -1.049959 -0.849921  \n",
       "3     3.835736 -0.230339  0.563578  1.188964  2.008685  1.217559  0.642179  \n",
       "4     1.114390 -0.479082  0.133153 -0.542894 -0.333704 -0.376796 -0.351644  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "4995  0.142246  0.699077  0.996773  0.166256  1.280191  0.274554 -0.328118  \n",
       "4996  0.414960 -0.179018  1.098301  0.604371  0.225461 -0.226670 -0.416019  \n",
       "4997  0.256927  0.185960 -0.227742 -0.293569  0.278287  1.436288  1.104163  \n",
       "4998  0.661162  1.687657  1.181948  1.291810  4.663536  4.970298  2.565401  \n",
       "4999 -0.148257 -0.536119 -0.268133 -0.066321  0.003022 -0.666711 -0.874664  \n",
       "\n",
       "[5000 rows x 24 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['NORM', 'NORM', 'NORM', ..., 'HYP', 'HYP', 'HYP'], dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Encode categorical labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 3, 3, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.448\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.39      0.41       196\n",
      "           1       0.56      0.66      0.60       224\n",
      "           2       0.36      0.35      0.36       186\n",
      "           3       0.48      0.55      0.51       202\n",
      "           4       0.33      0.24      0.28       192\n",
      "\n",
      "    accuracy                           0.45      1000\n",
      "   macro avg       0.43      0.44      0.43      1000\n",
      "weighted avg       0.44      0.45      0.44      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the Random Forest classifier\n",
    "rf_classifier = RandomForestClassifier()\n",
    "\n",
    "# Train the classifier\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = rf_classifier.predict(X_test)\n",
    "\n",
    "# Decode the predicted labels if needed\n",
    "y_pred_decoded = label_encoder.inverse_transform(y_pred)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Generate a classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Get feature importance scores from the trained model\n",
    "feature_importance = rf_classifier.feature_importances_\n",
    "\n",
    "# Create a DataFrame to store feature importance scores\n",
    "feature_importance_df = pd.DataFrame({'Feature Index': range(len(feature_importance)), 'Importance': feature_importance})\n",
    "\n",
    "# Sort features by importance (descending order)\n",
    "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Plotting feature importance\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(feature_importance_df['Feature Index'], feature_importance_df['Importance'])\n",
    "plt.xlabel('Importance Score')\n",
    "plt.ylabel('Feature Index')\n",
    "plt.title('Feature Importance in RandomForestClassifier')\n",
    "plt.show()\n",
    "\n",
    "# Display the sorted feature importance DataFrame\n",
    "print(\"Sorted Feature Importance:\")\n",
    "print(feature_importance_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model Accuracy: 0.445\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the parameter grid to search\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],  # Number of trees in the forest\n",
    "    'max_depth': [None, 10, 20],  # Maximum depth of the trees\n",
    "    'min_samples_split': [2, 5, 10],  # Minimum number of samples required to split a node\n",
    "    'min_samples_leaf': [1, 2, 4]  # Minimum number of samples required at each leaf node\n",
    "}\n",
    "\n",
    "# Initialize RandomForestClassifier\n",
    "rf_classifier = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=rf_classifier, param_grid=param_grid, cv=5)\n",
    "\n",
    "# Perform grid search to find the best hyperparameters\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best model from grid search\n",
    "best_rf_model = grid_search.best_estimator_\n",
    "\n",
    "# Evaluate the best model\n",
    "best_model_accuracy = best_rf_model.score(X_test, y_test)\n",
    "print(\"Best Model Accuracy:\", best_model_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Classifier Accuracy: 0.439\n",
      "SVM Classifier Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.30      0.37       196\n",
      "           1       0.56      0.62      0.59       224\n",
      "           2       0.33      0.41      0.37       186\n",
      "           3       0.43      0.63      0.51       202\n",
      "           4       0.35      0.19      0.24       192\n",
      "\n",
      "    accuracy                           0.44      1000\n",
      "   macro avg       0.43      0.43      0.42      1000\n",
      "weighted avg       0.44      0.44      0.42      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# Initialize the SVM classifier\n",
    "svm_classifier = SVC()\n",
    "\n",
    "# Train the SVM classifier\n",
    "svm_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set using SVM classifier\n",
    "y_pred_svm = svm_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the SVM classifier\n",
    "accuracy_svm = accuracy_score(y_test, y_pred_svm)\n",
    "print(\"SVM Classifier Accuracy:\", accuracy_svm)\n",
    "\n",
    "# Generate a classification report for SVM classifier\n",
    "print(\"SVM Classifier Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_svm))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting Classifier Accuracy: 0.439\n",
      "Voting Classifier Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.37      0.42       196\n",
      "           1       0.54      0.64      0.59       224\n",
      "           2       0.32      0.34      0.33       186\n",
      "           3       0.45      0.60      0.52       202\n",
      "           4       0.31      0.20      0.24       192\n",
      "\n",
      "    accuracy                           0.44      1000\n",
      "   macro avg       0.42      0.43      0.42      1000\n",
      "weighted avg       0.43      0.44      0.43      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# Initialize individual classifiers\n",
    "svm_classifier = SVC(probability=True)  # Set probability=True for predict_proba support\n",
    "rf_classifier = RandomForestClassifier()\n",
    "gb_classifier = GradientBoostingClassifier()\n",
    "\n",
    "# Create a voting classifier using 'soft' voting\n",
    "voting_classifier = VotingClassifier(\n",
    "    estimators=[('svm', svm_classifier), ('rf', rf_classifier), ('gb', gb_classifier)],\n",
    "    voting='soft'  # Use soft voting for probabilities\n",
    ")\n",
    "\n",
    "# Train the voting classifier\n",
    "voting_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set using voting classifier\n",
    "y_pred_voting = voting_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the voting classifier\n",
    "accuracy_voting = accuracy_score(y_test, y_pred_voting)\n",
    "print(\"Voting Classifier Accuracy:\", accuracy_voting)\n",
    "\n",
    "# Generate a classification report for voting classifier\n",
    "print(\"Voting Classifier Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_voting))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
